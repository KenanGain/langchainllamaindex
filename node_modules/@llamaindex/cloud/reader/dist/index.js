import { FileReader, Document } from '@llamaindex/core/schema';
import { getEnv, fs, path } from '@llamaindex/env';
import { filetypeinfo } from 'magic-bytes.js';
import { ParsingService } from '../../api/dist/index.js';

const e = /\{[^{}]+\}/g, t = ({ allowReserved: e, name: t, value: r })=>{
    if (null == r) return "";
    if ("object" == typeof r) throw new Error("Deeply-nested arrays/objects arenâ€™t supported. Provide your own `querySerializer()` to handle these.");
    return `${t}=${e ? r : encodeURIComponent(r)}`;
}, r = ({ allowReserved: e, explode: r, name: s, style: a, value: n })=>{
    if (!r) {
        const t = (e ? n : n.map((e)=>encodeURIComponent(e))).join(((e)=>{
            switch(e){
                case "form":
                default:
                    return ",";
                case "pipeDelimited":
                    return "|";
                case "spaceDelimited":
                    return "%20";
            }
        })(a));
        switch(a){
            case "label":
                return `.${t}`;
            case "matrix":
                return `;${s}=${t}`;
            case "simple":
                return t;
            default:
                return `${s}=${t}`;
        }
    }
    const o = ((e)=>{
        switch(e){
            case "label":
                return ".";
            case "matrix":
                return ";";
            case "simple":
                return ",";
            default:
                return "&";
        }
    })(a), l = n.map((r)=>"label" === a || "simple" === a ? e ? r : encodeURIComponent(r) : t({
            allowReserved: e,
            name: s,
            value: r
        })).join(o);
    return "label" === a || "matrix" === a ? o + l : l;
}, s = ({ allowReserved: e, explode: r, name: s, style: a, value: n })=>{
    if (n instanceof Date) return `${s}=${n.toISOString()}`;
    if ("deepObject" !== a && !r) {
        let t = [];
        Object.entries(n).forEach(([r, s])=>{
            t = [
                ...t,
                r,
                e ? s : encodeURIComponent(s)
            ];
        });
        const r = t.join(",");
        switch(a){
            case "form":
                return `${s}=${r}`;
            case "label":
                return `.${r}`;
            case "matrix":
                return `;${s}=${r}`;
            default:
                return r;
        }
    }
    const o = ((e)=>{
        switch(e){
            case "label":
                return ".";
            case "matrix":
                return ";";
            case "simple":
                return ",";
            default:
                return "&";
        }
    })(a), l = Object.entries(n).map(([r, n])=>t({
            allowReserved: e,
            name: "deepObject" === a ? `${s}[${r}]` : r,
            value: n
        })).join(o);
    return "label" === a || "matrix" === a ? o + l : l;
}, a = ({ allowReserved: e, array: a, object: n } = {})=>(o)=>{
        let l = [];
        if (o && "object" == typeof o) for(const i in o){
            const c = o[i];
            null != c && (l = Array.isArray(c) ? [
                ...l,
                r({
                    allowReserved: e,
                    explode: !0,
                    name: i,
                    style: "form",
                    value: c,
                    ...a
                })
            ] : "object" != typeof c ? [
                ...l,
                t({
                    allowReserved: e,
                    name: i,
                    value: c
                })
            ] : [
                ...l,
                s({
                    allowReserved: e,
                    explode: !0,
                    name: i,
                    style: "deepObject",
                    value: c,
                    ...n
                })
            ]);
        }
        return l.join("&");
    }, n = ({ baseUrl: a, path: n, query: o, querySerializer: l, url: i })=>{
    let c = a + (i.startsWith("/") ? i : `/${i}`);
    n && (c = (({ path: a, url: n })=>{
        let o = n;
        const l = n.match(e);
        if (l) for (const e of l){
            let n = !1, l = e.substring(1, e.length - 1), i = "simple";
            l.endsWith("*") && (n = !0, l = l.substring(0, l.length - 1)), l.startsWith(".") ? (l = l.substring(1), i = "label") : l.startsWith(";") && (l = l.substring(1), i = "matrix");
            const c = a[l];
            null != c && (o = Array.isArray(c) ? o.replace(e, r({
                explode: n,
                name: l,
                style: i,
                value: c
            })) : "object" != typeof c ? "matrix" !== i ? o.replace(e, "label" === i ? `.${c}` : c) : o.replace(e, `;${t({
                name: l,
                value: c
            })}`) : o.replace(e, s({
                explode: n,
                name: l,
                style: i,
                value: c
            })));
        }
        return o;
    })({
        path: n,
        url: c
    }));
    let u = o ? l(o) : "";
    return u.startsWith("?") && (u = u.substring(1)), u && (c += `?${u}`), c;
}, o = (e, t)=>{
    const r = {
        ...e,
        ...t
    };
    return r.baseUrl?.endsWith("/") && (r.baseUrl = r.baseUrl.substring(0, r.baseUrl.length - 1)), r.headers = l(e.headers, t.headers), r;
}, l = (...e)=>{
    const t = new Headers;
    for (const r of e){
        if (!r || "object" != typeof r) continue;
        const e = r instanceof Headers ? r.entries() : Object.entries(r);
        for (const [r, s] of e)if (null === s) t.delete(r);
        else if (Array.isArray(s)) for (const e of s)t.append(r, e);
        else void 0 !== s && t.set(r, "object" == typeof s ? JSON.stringify(s) : s);
    }
    return t;
};
class i {
    constructor(){
        this._fns = [];
    }
    eject(e) {
        const t = this._fns.indexOf(e);
        -1 !== t && (this._fns = [
            ...this._fns.slice(0, t),
            ...this._fns.slice(t + 1)
        ]);
    }
    use(e) {
        this._fns = [
            ...this._fns,
            e
        ];
    }
}
const d = {
    bodySerializer: (e)=>JSON.stringify(e)
}, h = a({
    allowReserved: !1,
    array: {
        explode: !0,
        style: "form"
    },
    object: {
        explode: !0,
        style: "deepObject"
    }
}), y = {
    "Content-Type": "application/json"
}, m = (e = {})=>({
        ...d,
        baseUrl: "",
        fetch: globalThis.fetch,
        headers: y,
        parseAs: "auto",
        querySerializer: h,
        ...e
    }), b = (e = {})=>{
    let t = o(m(), e);
    const r = ()=>({
            ...t
        }), s = {
        request: new i,
        response: new i
    }, c = async (e)=>{
        const r = {
            ...t,
            ...e,
            headers: l(t.headers, e.headers)
        };
        r.body && r.bodySerializer && (r.body = r.bodySerializer(r.body)), r.body || r.headers.delete("Content-Type");
        const o = n({
            baseUrl: r.baseUrl ?? "",
            path: r.path,
            query: r.query,
            querySerializer: "function" == typeof r.querySerializer ? r.querySerializer : a(r.querySerializer),
            url: r.url
        }), i = {
            redirect: "follow",
            ...r
        };
        let c = new Request(o, i);
        for (const e of s.request._fns)c = await e(c, r);
        const u = r.fetch;
        let d = await u(c);
        for (const e of s.response._fns)d = await e(d, c, r);
        const p = {
            request: c,
            response: d
        };
        if (d.ok) {
            if (204 === d.status || "0" === d.headers.get("Content-Length")) return {
                data: {},
                ...p
            };
            if ("stream" === r.parseAs) return {
                data: d.body,
                ...p
            };
            const e = ("auto" === r.parseAs ? ((e)=>{
                if (e) return e.startsWith("application/json") || e.endsWith("+json") ? "json" : "multipart/form-data" === e ? "formData" : [
                    "application/",
                    "audio/",
                    "image/",
                    "video/"
                ].some((t)=>e.startsWith(t)) ? "blob" : e.startsWith("text/") ? "text" : void 0;
            })(d.headers.get("Content-Type")) : r.parseAs) ?? "json";
            let t = await d[e]();
            return "json" === e && r.responseTransformer && (t = await r.responseTransformer(t)), {
                data: t,
                ...p
            };
        }
        let f = await d.text();
        if (r.throwOnError) throw new Error(f);
        try {
            f = JSON.parse(f);
        } catch  {}
        return {
            error: f || {},
            ...p
        };
    };
    return {
        connect: (e)=>c({
                ...e,
                method: "CONNECT"
            }),
        delete: (e)=>c({
                ...e,
                method: "DELETE"
            }),
        get: (e)=>c({
                ...e,
                method: "GET"
            }),
        getConfig: r,
        head: (e)=>c({
                ...e,
                method: "HEAD"
            }),
        interceptors: s,
        options: (e)=>c({
                ...e,
                method: "OPTIONS"
            }),
        patch: (e)=>c({
                ...e,
                method: "PATCH"
            }),
        post: (e)=>c({
                ...e,
                method: "POST"
            }),
        put: (e)=>c({
                ...e,
                method: "PUT"
            }),
        request: c,
        setConfig: (e)=>(t = o(t, e), r()),
        trace: (e)=>c({
                ...e,
                method: "TRACE"
            })
    };
};

async function sleep(ms) {
    return new Promise((resolve)=>setTimeout(resolve, ms));
}

const SUPPORT_FILE_EXT = [
    ".pdf",
    // document and presentations
    ".602",
    ".abw",
    ".cgm",
    ".cwk",
    ".doc",
    ".docx",
    ".docm",
    ".dot",
    ".dotm",
    ".hwp",
    ".key",
    ".lwp",
    ".mw",
    ".mcw",
    ".pages",
    ".pbd",
    ".ppt",
    ".pptm",
    ".pptx",
    ".pot",
    ".potm",
    ".potx",
    ".rtf",
    ".sda",
    ".sdd",
    ".sdp",
    ".sdw",
    ".sgl",
    ".sti",
    ".sxi",
    ".sxw",
    ".stw",
    ".sxg",
    ".txt",
    ".uof",
    ".uop",
    ".uot",
    ".vor",
    ".wpd",
    ".wps",
    ".xml",
    ".zabw",
    ".epub",
    // images
    ".jpg",
    ".jpeg",
    ".png",
    ".gif",
    ".bmp",
    ".svg",
    ".tiff",
    ".webp",
    // web
    ".htm",
    ".html",
    // spreadsheets
    ".xlsx",
    ".xls",
    ".xlsm",
    ".xlsb",
    ".xlw",
    ".csv",
    ".dif",
    ".sylk",
    ".slk",
    ".prn",
    ".numbers",
    ".et",
    ".ods",
    ".fods",
    ".uos1",
    ".uos2",
    ".dbf",
    ".wk1",
    ".wk2",
    ".wk3",
    ".wk4",
    ".wks",
    ".123",
    ".wq1",
    ".wq2",
    ".wb1",
    ".wb2",
    ".wb3",
    ".qpw",
    ".xlr",
    ".eth",
    ".tsv"
];
// Do not modify this variable or cause type errors
// eslint-disable-next-line no-var
var process;
/**
 * Represents a reader for parsing files using the LlamaParse API.
 * See https://github.com/run-llama/llama_parse
 */ class LlamaParseReader extends FileReader {
    #client;
    constructor(params = {}){
        super();
        // The base URL of the Llama Cloud Platform.
        this.baseUrl = "https://api.cloud.llamaindex.ai";
        // The result type for the parser.
        this.resultType = "text";
        // The interval in seconds to check if the parsing is done.
        this.checkInterval = 1;
        // The maximum timeout in seconds to wait for the parsing to finish.
        this.maxTimeout = 2000;
        // Whether to print the progress of the parsing.
        this.verbose = true;
        // The language of the text to parse.
        this.language = [
            "en"
        ];
        // Deprecated. Use vendorMultimodal params. Whether to use gpt-4o to extract text from documents.
        this.gpt4oMode = false;
        // Whether or not to ignore and skip errors raised during parsing.
        this.ignoreErrors = true;
        // Whether to split by page using the pageSeparator or '\n---\n' as default.
        this.splitByPage = true;
        // Whether to use the vendor multimodal API.
        this.useVendorMultimodalModel = false;
        Object.assign(this, params);
        this.language = Array.isArray(this.language) ? this.language : [
            this.language
        ];
        this.stdout = params.stdout ?? typeof process !== "undefined" ? process.stdout : undefined;
        const apiKey = params.apiKey ?? getEnv("LLAMA_CLOUD_API_KEY");
        if (!apiKey) {
            throw new Error("API Key is required for LlamaParseReader. Please pass the apiKey parameter or set the LLAMA_CLOUD_API_KEY environment variable.");
        }
        this.apiKey = apiKey;
        if (this.baseUrl.endsWith("/")) {
            this.baseUrl = this.baseUrl.slice(0, -"/".length);
        }
        if (this.baseUrl.endsWith("/api/parsing")) {
            this.baseUrl = this.baseUrl.slice(0, -"/api/parsing".length);
        }
        if (params.gpt4oMode) {
            params.gpt4oApiKey = params.gpt4oApiKey ?? getEnv("LLAMA_CLOUD_GPT4O_API_KEY");
            this.gpt4oApiKey = params.gpt4oApiKey;
        }
        if (params.useVendorMultimodalModel) {
            params.vendorMultimodalApiKey = params.vendorMultimodalApiKey ?? getEnv("LLAMA_CLOUD_VENDOR_MULTIMODAL_API_KEY");
            this.vendorMultimodalApiKey = params.vendorMultimodalApiKey;
        }
        this.#client = b(m({
            headers: {
                Authorization: `Bearer ${this.apiKey}`
            },
            baseUrl: this.baseUrl
        }));
    }
    // Create a job for the LlamaParse API
    async createJob(data) {
        // Load data, set the mime type
        const { mime } = await LlamaParseReader.getMimeType(data);
        if (this.verbose) {
            console.log("Started uploading the file");
        }
        const body = {
            file: new Blob([
                data
            ], {
                type: mime
            }),
            language: this.language,
            parsing_instruction: this.parsingInstruction,
            skip_diagonal_text: this.skipDiagonalText,
            invalidate_cache: this.invalidateCache,
            do_not_cache: this.doNotCache,
            fast_mode: this.fastMode,
            do_not_unroll_columns: this.doNotUnrollColumns,
            page_separator: this.pageSeparator,
            page_prefix: this.pagePrefix,
            page_suffix: this.pageSuffix,
            gpt4o_mode: this.gpt4oMode,
            gpt4o_api_key: this.gpt4oApiKey,
            bounding_box: this.boundingBox,
            target_pages: this.targetPages,
            use_vendor_multimodal_model: this.useVendorMultimodalModel,
            vendor_multimodal_model_name: this.vendorMultimodalModelName,
            vendor_multimodal_api_key: this.vendorMultimodalApiKey,
            premium_mode: this.premiumMode,
            webhook_url: this.webhookUrl,
            take_screenshot: this.takeScreenshot,
            disable_ocr: this.disableOcr,
            disable_reconstruction: this.disableReconstruction,
            input_s3_path: this.inputS3Path,
            output_s3_path_prefix: this.outputS3PathPrefix
        };
        const response = await ParsingService.uploadFileApiV1ParsingUploadPost({
            client: this.#client,
            throwOnError: true,
            signal: AbortSignal.timeout(this.maxTimeout * 1000),
            body
        });
        return response.data.id;
    }
    // Get the result of the job
    async getJobResult(jobId, resultType) {
        const signal = AbortSignal.timeout(this.maxTimeout * 1000);
        let tries = 0;
        while(true){
            await sleep(this.checkInterval * 1000);
            // Check the job status. If unsuccessful response, checks if maximum timeout has been reached. If reached, throws an error
            const result = await ParsingService.getJobApiV1ParsingJobJobIdGet({
                client: this.#client,
                throwOnError: true,
                path: {
                    job_id: jobId
                },
                signal
            });
            const { data } = result;
            const status = data["status"];
            // If job has completed, return the result
            if (status === "SUCCESS") {
                let result;
                switch(resultType){
                    case "json":
                        {
                            result = await ParsingService.getJobJsonResultApiV1ParsingJobJobIdResultJsonGet({
                                client: this.#client,
                                throwOnError: true,
                                path: {
                                    job_id: jobId
                                },
                                signal
                            });
                            break;
                        }
                    case "markdown":
                        {
                            result = await ParsingService.getJobResultApiV1ParsingJobJobIdResultMarkdownGet({
                                client: this.#client,
                                throwOnError: true,
                                path: {
                                    job_id: jobId
                                },
                                signal
                            });
                            break;
                        }
                    case "text":
                        {
                            result = await ParsingService.getJobTextResultApiV1ParsingJobJobIdResultTextGet({
                                client: this.#client,
                                throwOnError: true,
                                path: {
                                    job_id: jobId
                                },
                                signal
                            });
                            break;
                        }
                }
                return result.data;
            // If job is still pending, check if maximum timeout has been reached. If reached, throws an error
            } else if (status === "PENDING") {
                signal.throwIfAborted();
                if (this.verbose && tries % 10 === 0) {
                    this.stdout?.write(".");
                }
                tries++;
            } else {
                throw new Error(`Failed to parse the file: ${jobId}, status: ${status}`);
            }
        }
    }
    /**
   * Loads data from a file and returns an array of Document objects.
   * To be used with resultType = "text" and "markdown"
   *
   * @param {Uint8Array} fileContent - The content of the file to be loaded.
   * @return {Promise<Document[]>} A Promise object that resolves to an array of Document objects.
   */ async loadDataAsContent(fileContent) {
        return this.createJob(fileContent).then(async (jobId)=>{
            if (this.verbose) {
                console.log(`Started parsing the file under job id ${jobId}`);
            }
            // Return results as Document objects
            const jobResults = await this.getJobResult(jobId, this.resultType);
            const resultText = jobResults[this.resultType];
            // Split the text by separator if splitByPage is true
            if (this.splitByPage) {
                return this.splitTextBySeparator(resultText);
            }
            return [
                new Document({
                    text: resultText
                })
            ];
        }).catch((error)=>{
            if (this.ignoreErrors) {
                console.warn(`Error while parsing the file: ${error.message}`);
                return [];
            } else {
                throw error;
            }
        });
    }
    /**
   * Loads data from a file and returns an array of JSON objects.
   * To be used with resultType = "json"
   *
   * @param {string} filePathOrContent - The file path to the file or the content of the file as a Buffer
   * @return {Promise<Record<string, any>[]>} A Promise that resolves to an array of JSON objects.
   */ async loadJson(filePathOrContent) {
        let jobId;
        const isFilePath = typeof filePathOrContent === "string";
        try {
            const data = isFilePath ? await fs.readFile(filePathOrContent) : filePathOrContent;
            // Creates a job for the file
            jobId = await this.createJob(data);
            if (this.verbose) {
                console.log(`Started parsing the file under job id ${jobId}`);
            }
            // Return results as an array of JSON objects (same format as Python version of the reader)
            const resultJson = await this.getJobResult(jobId, "json");
            resultJson.job_id = jobId;
            resultJson.file_path = isFilePath ? filePathOrContent : undefined;
            return [
                resultJson
            ];
        } catch (e) {
            if (this.ignoreErrors) {
                console.error(`Error while parsing the file under job id ${jobId}`, e);
                return [];
            } else {
                throw e;
            }
        }
    }
    /**
   * Downloads and saves images from a given JSON result to a specified download path.
   * Currently only supports resultType = "json"
   *
   * @param {Record<string, any>[]} jsonResult - The JSON result containing image information.
   * @param {string} downloadPath - The path to save the downloaded images.
   * @return {Promise<Record<string, any>[]>} A Promise that resolves to an array of image objects.
   */ async getImages(jsonResult, downloadPath) {
        try {
            // Create download directory if it doesn't exist (Actually check for write access, not existence, since fsPromises does not have a `existsSync` method)
            try {
                await fs.access(downloadPath);
            } catch  {
                await fs.mkdir(downloadPath, {
                    recursive: true
                });
            }
            const images = [];
            for (const result of jsonResult){
                const jobId = result.job_id;
                for (const page of result.pages){
                    if (this.verbose) {
                        console.log(`> Image for page ${page.page}: ${page.images}`);
                    }
                    for (const image of page.images){
                        const imageName = image.name;
                        const imagePath = await this.getImagePath(downloadPath, jobId, imageName);
                        await this.fetchAndSaveImage(imageName, imagePath, jobId);
                        // Assign metadata to the image
                        image.path = imagePath;
                        image.job_id = jobId;
                        image.original_pdf_path = result.file_path;
                        image.page_number = page.page;
                        images.push(image);
                    }
                }
            }
            return images;
        } catch (e) {
            console.error(`Error while downloading images from the parsed result`, e);
            if (this.ignoreErrors) {
                return [];
            } else {
                throw e;
            }
        }
    }
    async getImagePath(downloadPath, jobId, imageName) {
        return path.join(downloadPath, `${jobId}-${imageName}`);
    }
    async fetchAndSaveImage(imageName, imagePath, jobId) {
        const response = await ParsingService.getJobImageResultApiV1ParsingJobJobIdResultImageNameGet({
            client: this.#client,
            path: {
                job_id: jobId,
                name: imageName
            }
        });
        if (response.error) {
            throw new Error(`Failed to download image: ${response.error.detail}`);
        }
        const blob = await response.data;
        // Write the image buffer to the specified imagePath
        await fs.writeFile(imagePath, new Uint8Array(await blob.arrayBuffer()));
    }
    // Filters out invalid values (null, undefined, empty string) of specific params.
    filterSpecificParams(params, keysToCheck) {
        const filteredParams = {};
        for (const [key, value] of Object.entries(params)){
            if (keysToCheck.includes(key)) {
                if (value !== null && value !== undefined && value !== "") {
                    filteredParams[key] = value;
                }
            } else {
                filteredParams[key] = value;
            }
        }
        return filteredParams;
    }
    splitTextBySeparator(text) {
        const separator = this.pageSeparator ?? "\n---\n";
        const textChunks = text.split(separator);
        return textChunks.map((docChunk)=>new Document({
                text: docChunk
            }));
    }
    static async getMimeType(data) {
        const typeinfos = filetypeinfo(data);
        // find the first type info that matches the supported MIME types
        // It could be happened that docx file is recognized as zip file, so we need to check the mime type
        const info = typeinfos.find((info)=>{
            if (info.extension && SUPPORT_FILE_EXT.includes(`.${info.extension}`)) {
                return info;
            }
        });
        if (!info || !info.mime || !info.extension) {
            const ext = SUPPORT_FILE_EXT.join(", ");
            throw new Error(`File has type which does not match supported MIME Types. Supported formats include: ${ext}`);
        }
        return {
            mime: info.mime,
            extension: info.extension
        };
    }
}

export { LlamaParseReader };
